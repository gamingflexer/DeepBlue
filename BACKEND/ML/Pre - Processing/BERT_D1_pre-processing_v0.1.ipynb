{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cc8340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93abd07d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68c5549",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f3ac15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 72. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Cinderella is the only daughter of an affluent and widower duke who has rewed to provide her with a stepmom and two stepsisters . Cinderellas mother died due to illness when she was still a young girl, leaving a doll, favorite dress, and a pair of glass slippers .'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Cinderella came from a great family. She is the only daughter of an affluent and widower duke who has rewed to provide her with a stepmom and two stepsisters. Cinderellas mother died due to illness when she was still a young girl, leaving her with a doll, favorite dress, and a pair of glass slippers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b0e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1d35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 21:32:59.441595: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-22 21:32:59.442022: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dslim/bert-large-NER\"\n",
    "# This model only exists in PyTorch, so we use the `from_pt` flag to import that model in TensorFlow.\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#classifier = pipeline('', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf4aeefa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#data = pd.read_csv('/Users/cosmos/Desktop/DeepBlue/BACKEND/Datasets/Main/resume_dataset.csv')\n",
    "#data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5435a598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e8b0ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "      <th>extras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhishek Jha\\nApplication Development Associat...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n",
       "      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n",
       "      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Abhishek Jha\\nApplication Development Associat...   \n",
       "1  Afreen Jamadar\\nActive member of IIIT Committe...   \n",
       "2  Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n",
       "3  Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n",
       "4  Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n",
       "\n",
       "                                          annotation  extras  \n",
       "0  [{'label': ['Skills'], 'points': [{'start': 12...     NaN  \n",
       "1  [{'label': ['Email Address'], 'points': [{'sta...     NaN  \n",
       "2  [{'label': ['Skills'], 'points': [{'start': 37...     NaN  \n",
       "3  [{'label': ['Skills'], 'points': [{'start': 80...     NaN  \n",
       "4  [{'label': ['Degree'], 'points': [{'start': 20...     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "data = pd.read_json(\"NER_RESUME.json\", lines = True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f501019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40ca0ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Abhishek Jha Application Development Associate...\n",
       "1    Afreen Jamadar Active member of IIIT Committee...\n",
       "2    Akhil Yadav Polemaina Hyderabad, Telangana - E...\n",
       "3    Alok Khandai Operational Analyst (SQL DBA) Eng...\n",
       "4    Ananya Chavan lecturer - oracle tutorials  Mum...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data preprocessing\n",
    "\n",
    "\n",
    "data[\"content\"] = data[\"content\"].apply(lambda x: x.replace(\"\\n\", \" \"))\n",
    "data[\"content\"].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cabcafe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220 entries, 0 to 219\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   content     220 non-null    object \n",
      " 1   annotation  220 non-null    object \n",
      " 2   extras      0 non-null      float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ad3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "import json\n",
    "import re\n",
    "\n",
    "# JSON formatting functions\n",
    "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
    "    training_data = []\n",
    "    lines=[]\n",
    "    with open(dataturks_JSON_FilePath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        text = data['content'].replace(\"\\n\", \" \")\n",
    "        entities = []\n",
    "        data_annotations = data['annotation']\n",
    "        if data_annotations is not None:\n",
    "            for annotation in data_annotations:\n",
    "                #only a single point in text annotation.\n",
    "                point = annotation['points'][0]\n",
    "                labels = annotation['label']\n",
    "                # handle both list of labels or a single label.\n",
    "                if not isinstance(labels, list):\n",
    "                    labels = [labels]\n",
    "\n",
    "                for label in labels:\n",
    "                    point_start = point['start']\n",
    "                    point_end = point['end']\n",
    "                    point_text = point['text']\n",
    "\n",
    "                    lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
    "                    rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
    "                    if lstrip_diff != 0:\n",
    "                        point_start = point_start + lstrip_diff\n",
    "                    if rstrip_diff != 0:\n",
    "                        point_end = point_end - rstrip_diff\n",
    "                    entities.append((point_start, point_end + 1 , label))\n",
    "        training_data.append((text, {\"entities\" : entities}))\n",
    "    return training_data\n",
    "\n",
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "        data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "    Returns:\n",
    "        list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                    text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(\n",
    "                    text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d9967ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Abhishek Jha Application Development Associate - Accenture  Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a  • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE  Application Development Associate  Accenture -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION  B.E in Information science and engineering  B.v.b college of engineering and technology -  Hubli, Karnataka  August 2013 to June 2017  12th in Mathematics  Woodbine modern school  April 2011 to March 2013  10th  Kendriya Vidyalaya  April 2001 to March 2011  SKILLS  C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)  ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN   • Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player\",\n",
       " {'entities': [[1296, 1622, 'Skills'],\n",
       "   [993, 1154, 'Skills'],\n",
       "   [939, 957, 'College Name'],\n",
       "   [883, 905, 'College Name'],\n",
       "   [856, 860, 'Graduation Year'],\n",
       "   [771, 814, 'College Name'],\n",
       "   [727, 769, 'Designation'],\n",
       "   [407, 416, 'Companies worked at'],\n",
       "   [372, 405, 'Designation'],\n",
       "   [95, 145, 'Email Address'],\n",
       "   [60, 69, 'Location'],\n",
       "   [49, 58, 'Companies worked at'],\n",
       "   [13, 46, 'Designation'],\n",
       "   [0, 12, 'Name']]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = trim_entity_spans(convert_dataturks_to_spacy(\"NER_RESUME.json\"))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f2aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlapping Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0684e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entities(training_data):\n",
    "    \n",
    "    clean_data = []\n",
    "    for text, annotation in training_data:\n",
    "        \n",
    "        entities = annotation.get('entities')\n",
    "        entities_copy = entities.copy()\n",
    "        \n",
    "        # append entity only if it is longer than its overlapping entity\n",
    "        i = 0\n",
    "        for entity in entities_copy:\n",
    "            j = 0\n",
    "            for overlapping_entity in entities_copy:\n",
    "                # Skip self\n",
    "                if i != j:\n",
    "                    e_start, e_end, oe_start, oe_end = entity[0], entity[1], overlapping_entity[0], overlapping_entity[1]\n",
    "                    # Delete any entity that overlaps, keep if longer\n",
    "                    if ((e_start >= oe_start and e_start <= oe_end) \\\n",
    "                    or (e_end <= oe_end and e_end >= oe_start)) \\\n",
    "                    and ((e_end - e_start) <= (oe_end - oe_start)):\n",
    "                        entities.remove(entity)\n",
    "                j += 1\n",
    "            i += 1\n",
    "        clean_data.append((text, {'entities': entities}))\n",
    "                \n",
    "    return clean_data\n",
    "\n",
    "data = clean_entities(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "337dfdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72bc19dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cosmos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Changing data to appropriate format so as to feed it to the model\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "df_data = pd.DataFrame(columns = [\"clean_content\", \"entities_mapped\"])\n",
    "\n",
    "entities_mapped = []\n",
    "clean_content = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    content = data[i][0].split()\n",
    "    entities = data[i][1][\"entities\"]\n",
    "    words = []\n",
    "    labels = []\n",
    "    \n",
    "    for word in content:\n",
    "        if (word.isalnum() or word.find(\".com\") != -1) and word not in en_stops:\n",
    "            words.append(word)\n",
    "            found = False\n",
    "            for entity in sorted(entities):\n",
    "                ent_start = entity[0]\n",
    "                ent_end = entity[1]\n",
    "                ent_label = entity[2]\n",
    "\n",
    "                if word in data[i][0][ent_start: ent_end].split(): \n",
    "                    labels.append(ent_label)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                labels.append(\"O\")\n",
    "    \n",
    "    entities_mapped.append(labels)\n",
    "    clean_content.append(words)\n",
    "    \n",
    "    \n",
    "df_data[\"entities_mapped\"] = entities_mapped\n",
    "df_data[\"clean_content\"] = clean_content\n",
    "df_data[\"clean_content\"] = df_data[\"clean_content\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b7eaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_content</th>\n",
       "      <th>entities_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhishek Jha Application Development Associate...</td>\n",
       "      <td>[Name, Name, Designation, Designation, Designa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afreen Jamadar Active member IIIT Committee Th...</td>\n",
       "      <td>[Name, Name, O, O, O, O, O, O, O, O, Email Add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akhil Yadav Polemaina Telangana Email indeed.c...</td>\n",
       "      <td>[Name, Name, Name, O, O, Email Address, Email ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alok Khandai Operational Analyst Engineer UNIS...</td>\n",
       "      <td>[Name, Name, Designation, Designation, Designa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ananya Chavan lecturer oracle tutorials Mahara...</td>\n",
       "      <td>[Name, Name, Designation, Companies worked at,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_content  \\\n",
       "0  Abhishek Jha Application Development Associate...   \n",
       "1  Afreen Jamadar Active member IIIT Committee Th...   \n",
       "2  Akhil Yadav Polemaina Telangana Email indeed.c...   \n",
       "3  Alok Khandai Operational Analyst Engineer UNIS...   \n",
       "4  Ananya Chavan lecturer oracle tutorials Mahara...   \n",
       "\n",
       "                                     entities_mapped  \n",
       "0  [Name, Name, Designation, Designation, Designa...  \n",
       "1  [Name, Name, O, O, O, O, O, O, O, O, Email Add...  \n",
       "2  [Name, Name, Name, O, O, Email Address, Email ...  \n",
       "3  [Name, Name, Designation, Designation, Designa...  \n",
       "4  [Name, Name, Designation, Companies worked at,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dad66bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Abhishek Jha Application Development Associate...\n",
       "1      Afreen Jamadar Active member IIIT Committee Th...\n",
       "2      Akhil Yadav Polemaina Telangana Email indeed.c...\n",
       "3      Alok Khandai Operational Analyst Engineer UNIS...\n",
       "4      Ananya Chavan lecturer oracle tutorials Mahara...\n",
       "                             ...                        \n",
       "215    Mansi Thanki Student Gujarat Email indeed.com/...\n",
       "216    Anil Kumar Microsoft Azure Delhi Email indeed....\n",
       "217    Siddharth Choudhary Microsoft Office Suite Exp...\n",
       "218    Valarmathi Dhandapani Investment Banking Karna...\n",
       "219    Pradeep Kumar Security Analyst Infosys Career ...\n",
       "Name: clean_content, Length: 220, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[\"clean_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6fa2049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220 entries, 0 to 219\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   clean_content    220 non-null    object\n",
      " 1   entities_mapped  220 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bae66f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "n_labels = len(set([e for entity in df_data[\"entities_mapped\"].values for e in entity]))\n",
    "print(n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ba56962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_csv(\"cleaned_resume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcfabe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQQklEQVR4nO3da7BdZX3H8e/PRISgFFICjUA90MmgjFNLjC2ItQrSKihop7Z0pE0tSme0rZfOaFCn2hfOYGvxUjtqvE1EtAIiUKhVjJdOXxQMQrkFGhSESCRHOxVFR0D/fbFXdJOcJPsczjr7bJ7vZ2bPXutZt/+Tc/I7az977bVTVUiS2vGYcRcgSVpYBr8kNcbgl6TGGPyS1BiDX5Ias3TcBYzi4IMPrqmpqXGXIUkT5dprr/1uVa3YuX0ign9qaopNmzaNuwxJmihJvjVTu0M9ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmIn45O4jMbXuyrEd+85zTx3bsSVpdzzjl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmN6Df4kr0tyc5Kbknwqyb5Jlie5KsmW7vmgPmuQJD1cb8Gf5DDgr4E1VfVUYAlwBrAO2FhVq4CN3bwkaYH0PdSzFNgvyVJgGXAPcDqwoVu+AXhxzzVIkob0FvxV9W3gncBdwDbg+1X1BeDQqtrWrbMNOGSm7ZOcnWRTkk3T09N9lSlJzelzqOcgBmf3RwJPBPZPcuao21fV+qpaU1VrVqxY0VeZktScPod6ngfcUVXTVfUgcAnwTODeJCsBuuftPdYgSdpJn8F/F3BckmVJApwEbAYuB9Z266wFLuuxBknSTpb2teOqujrJxcDXgYeA64D1wOOBC5OcxeCPw0v7qkGStKvegh+gqt4KvHWn5p8wOPuXJI2Bn9yVpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5Ia02vwJzkwycVJbk2yOcnxSZYnuSrJlu75oD5rkCQ9XN9n/O8B/r2qngw8DdgMrAM2VtUqYGM3L0laICMFf5KnznbHSQ4Ang18BKCqHqiq/wNOBzZ0q20AXjzbfUuS5m7UM/4PJLkmyauSHDjiNkcB08DHklyX5MNJ9gcOraptAN3zITNtnOTsJJuSbJqenh7xkJKkvRkp+KvqWcDLgCOATUk+meTkvWy2FFgNvL+qjgXuZxbDOlW1vqrWVNWaFStWjLqZJGkvRh7jr6otwFuANwK/A7y3e9P293ezyVZga1Vd3c1fzOAPwb1JVgJ0z9vnWrwkafZGHeP/9STvYvDm7InAi6rqKd30u2bapqq+A9yd5Oiu6STgFuByYG3Xtha4bO7lS5Jma+mI670P+BDwpqr68Y7GqronyVv2sN1fARck2Qf4JvByBn9sLkxyFnAX8NI5VS5JmpNRg/8U4MdV9VOAJI8B9q2qH1XV+bvbqKquB9bMsOik2RYqSZofo47xfxHYb2h+WdcmSZowowb/vlX1wx0z3fSyfkqSJPVp1OC/P8nqHTNJng78eA/rS5IWqVHH+F8LXJTknm5+JfBHvVQkSerVSMFfVV9L8mTgaCDArVX1YK+VSZJ6MeoZP8AzgKlum2OTUFUf76UqSVJvRgr+JOcDvwZcD/y0ay7A4JekCTPqGf8a4Jiqqj6LkST1b9Srem4CfqXPQiRJC2PUM/6DgVuSXAP8ZEdjVZ3WS1WPElPrrhzLce8899SxHFfSZBg1+N/WZxGSpIUz6uWcX03yJGBVVX0xyTJgSb+lSZL6MOptmV/J4H76H+yaDgMu7akmSVKPRn1z99XACcB98PMvZZnxKxMlSYvbqMH/k6p6YMdMkqUMruOXJE2YUYP/q0neBOzXfdfuRcC/9leWJKkvowb/OmAauBH4C+DfGHz/riRpwox6Vc/PGHz14of6LUeS1LdR79VzBzOM6VfVUfNekSSpV7O5V88O+zL4gvTl81+OJKlvI43xV9X3hh7frqp3Ayf2W5okqQ+jDvWsHpp9DINXAE/opSJJUq9GHer5x6Hph4A7gT+c92okSb0b9aqe5/ZdiCRpYYw61PP6PS2vqvPmpxxJUt9mc1XPM4DLu/kXAf8B3N1HUZKk/szmi1hWV9UPAJK8Dbioql7RV2GSpH6MesuGXwUeGJp/AJia92okSb0b9Yz/fOCaJJ9l8AnelwAf760qSVJvRr2q5+1JPgf8dtf08qq6rr+yJEl9GXWoB2AZcF9VvQfYmuTInmqSJPVo1K9efCvwRuCcrumxwCf6KkqS1J9Rz/hfApwG3A9QVffgLRskaSKNGvwPVFXR3Zo5yf79lSRJ6tOowX9hkg8CByZ5JfBFRvxSliRLklyX5IpufnmSq5Js6Z4PmlvpkqS52GvwJwnwaeBi4DPA0cDfVtU/jXiM1wCbh+bXARurahWwsZuXJC2QvV7OWVWV5NKqejpw1Wx2nuRw4FTg7cCO+/2cDjynm94AfIXBG8eSpAUw6lDPfyV5xhz2/27gDcDPhtoOraptAN3zIXPYryRpjkYN/ucyCP9vJLkhyY1JbtjTBkleCGyvqmvnUliSs5NsSrJpenp6LruQJM1gj0M9SX61qu4CXjCHfZ8AnJbkFAbf03tAkk8A9yZZWVXbkqwEts+0cVWtB9YDrFmzZpcvepckzc3ezvgvBaiqbwHnVdW3hh972rCqzqmqw6tqCjgD+FJVncng1s5ru9XWApc9kg5IkmZnb8Gfoemj5umY5wInJ9kCnNzNS5IWyN6u6qndTM9KVX2FwdU7VNX3gJPmui/t3dS6K8dy3DvPPXUsx5U0O3sL/qcluY/Bmf9+3TTdfFXVAb1WJ0mad3sM/qpaslCFSJIWxmxuyyxJehQw+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mN6S34kxyR5MtJNie5OclruvblSa5KsqV7PqivGiRJu+rzjP8h4G+q6inAccCrkxwDrAM2VtUqYGM3L0laIL0Ff1Vtq6qvd9M/ADYDhwGnAxu61TYAL+6rBknSrhZkjD/JFHAscDVwaFVtg8EfB+CQ3WxzdpJNSTZNT08vRJmS1ITegz/J44HPAK+tqvtG3a6q1lfVmqpas2LFiv4KlKTG9Br8SR7LIPQvqKpLuuZ7k6zslq8EtvdZgyTp4fq8qifAR4DNVXXe0KLLgbXd9Frgsr5qkCTtammP+z4B+BPgxiTXd21vAs4FLkxyFnAX8NIea5Ak7aS34K+q/wSym8Un9XVcSdKe+cldSWqMwS9JjTH4JakxBr8kNcbgl6TG9Hk5pxozte7KsR37znNPHduxpUnjGb8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGuNN2vSoMK4bxHlzOE0iz/glqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1Bhv0iZNKG9Mp7nyjF+SGuMZv/QIjOuse5zG2edxvdp4tPXZM35JasxYgj/J85PcluT2JOvGUYMktWrBh3qSLAH+GTgZ2Ap8LcnlVXXLQtciabK0OLTWh3Gc8f8mcHtVfbOqHgD+BTh9DHVIUpPG8ebuYcDdQ/Nbgd/aeaUkZwNnd7M/THLbHvZ5MPDdeatwPOzD4jDpfZj0+sE+PEze8Yg2f9JMjeMI/szQVrs0VK0H1o+0w2RTVa15pIWNk31YHCa9D5NeP9iHhTCOoZ6twBFD84cD94yhDklq0jiC/2vAqiRHJtkHOAO4fAx1SFKTFnyop6oeSvKXwOeBJcBHq+rmR7jbkYaEFjn7sDhMeh8mvX6wD71L1S7D65KkRzE/uStJjTH4JakxEx/8i/X2D0mOSPLlJJuT3JzkNV378iRXJdnSPR80tM05XT9uS/J7Q+1PT3Jjt+y9SWa6JLbPvixJcl2SKyaxD0kOTHJxklu7n8fxk9SHJK/rfoduSvKpJPsu9vqTfDTJ9iQ3DbXNW81JHpfk01371UmmFqgP/9D9Ht2Q5LNJDlzMfditqprYB4M3h78BHAXsA/w3cMy46+pqWwms7qafAPwPcAzw98C6rn0d8I5u+piu/scBR3b9WtItuwY4nsFnID4HvGCB+/J64JPAFd38RPUB2AC8opveBzhwUvrA4AOPdwD7dfMXAn+22OsHng2sBm4aapu3moFXAR/ops8APr1AffhdYGk3/Y7F3ofd9m2hDtTTL9fxwOeH5s8Bzhl3Xbup9TIG9ye6DVjZta0EbpupdgZXPR3frXPrUPsfAx9cwLoPBzYCJ/KL4J+YPgAHMAjO7NQ+EX3gF590X87gKrwruvBZ9PUDUzuF5rzVvGOdbnopg0/Jpu8+7LTsJcAFi70PMz0mfahnpts/HDamWnarewl3LHA1cGhVbQPong/pVttdXw7rpnduXyjvBt4A/GyobZL6cBQwDXysG676cJL9mZA+VNW3gXcCdwHbgO9X1ReYkPp3Mp81/3ybqnoI+D7wy71VPrM/Z3AG/7B6Oou6D5Me/CPd/mGckjwe+Azw2qq6b0+rztBWe2jvXZIXAtur6tpRN5mhbax9YHAmtRp4f1UdC9zPYJhhdxZVH7px8NMZDB88Edg/yZl72mSGtnH/DPZmLjWPtT9J3gw8BFywl3oWZR8mPfgX9e0fkjyWQehfUFWXdM33JlnZLV8JbO/ad9eXrd30zu0L4QTgtCR3MriL6olJPsFk9WErsLWqru7mL2bwh2BS+vA84I6qmq6qB4FLgGcyOfUPm8+af75NkqXALwH/21vlQ5KsBV4IvKy6cRomrA+THvyL9vYP3Tv3HwE2V9V5Q4suB9Z202sZjP3vaD+je6f/SGAVcE33kvgHSY7r9vmnQ9v0qqrOqarDq2qKwb/tl6rqzAnrw3eAu5Mc3TWdBNwyQX24CzguybLuuCcBmyeo/mHzWfPwvv6Awe/mQrwCez7wRuC0qvrR0KKJ6QMw2W/udv9GpzC4YuYbwJvHXc9QXc9i8LLtBuD67nEKgzG8jcCW7nn50DZv7vpxG0NXXABrgJu6Ze9jgd4A2qk/z+EXb+5OVB+A3wA2dT+LS4GDJqkPwN8Bt3bHPp/BlSOLun7gUwzek3iQwZntWfNZM7AvcBFwO4OrZo5aoD7czmBcfsf/6Q8s5j7s7uEtGySpMZM+1CNJmiWDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXm/wGRzSmvlJHnOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_data['clean_content'].apply(len).plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a647ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
