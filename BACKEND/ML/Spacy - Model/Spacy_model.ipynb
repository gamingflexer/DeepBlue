{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f7ffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.2.1-cp38-cp38-win_amd64.whl (12.2 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (20.9)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp38-cp38-win_amd64.whl (1.0 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp38-cp38-win_amd64.whl (36 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp38-cp38-win_amd64.whl (21 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp38-cp38-win_amd64.whl (113 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.59.0)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp38-cp38-win_amd64.whl (6.6 MB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.20.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp38-cp38-win_amd64.whl (452 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, pydantic, preshed, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "Successfully installed blis-0.7.5 catalogue-2.0.6 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.6 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0 wasabi-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ec9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2171fd62",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path of the file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3ad58999926f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_date\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'path of the file'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path of the file'"
     ]
    }
   ],
   "source": [
    "train_date= pickle.load(open('','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading spacy trained-blank model - en - english\n",
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fd766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the traning model\n",
    "\n",
    "def train_model(train_data):\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner=nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner,last=True)\n",
    "        \n",
    "    for _, annotation in train_data:\n",
    "        for ent in annotation['entities']:\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "# Now to remove other pipelines - we define this here - READ SPACY WEBSITE\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(10):\n",
    "            print(\"Statring iteration \" + str(itn))\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            index = 0\n",
    "            for text, annotations in train_data:\n",
    "                try:\n",
    "                    nlp.update(\n",
    "                        [text],  # batch of texts\n",
    "                        [annotations],  # batch of annotations\n",
    "                        drop=0.2,  # dropout - make it harder to memorise data\n",
    "                        sgd=optimizer,  # callable to update weights\n",
    "                        losses=losses)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                \n",
    "            print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing the trained data & TRAINNING DATA\n",
    "\n",
    "train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ee882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "nlp.to_disk('nlp_model_V0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load this already trained model - we use this\n",
    "\n",
    "nlp_model = spacy.load('model name + path')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your testing data\n",
    "\n",
    "test_data= pickle.load(open('path of the file','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f969077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have data in similarly segreagetd form we can use this otherwise not\n",
    "\n",
    "doc = nlp_model(test_data[0][0])\n",
    "for ent in docs.ent:\n",
    "    print (f'{ent. label_. upper (): {30}}- {ent. text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad73e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be4a5cbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## To Convert pdf into the data form required we use this\\n\\n\\n-docx extenstion\\n-Images\\n-Other Extension\\n\\n# !pip install PyMuPDF\\n#triedIPyPDF2 but does not work properly.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''## To Convert pdf into the data form required we use this\n",
    "\n",
    "\n",
    "-docx extenstion\n",
    "-Images\n",
    "-Other Extension\n",
    "\n",
    "# !pip install PyMuPDF\n",
    "#triedIPyPDF2 but does not work properly.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee0532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580fa8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, fitz\n",
    "fname = 'pdf path'\n",
    "doc = fitz.open(fname)\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text = text + str(page.getText())\n",
    "\n",
    "# removing spacing between lines    \n",
    "tx = \"\".join(text.split('\\n'))\n",
    "print (text)\n",
    "\n",
    "#and then add the test data oce again \n",
    "\n",
    "doc = nlp_model(text) # add the data varaible in the brackets\n",
    "for ent in docs.ent:\n",
    "    print (f'{ent. label_. upper (): {30}}- {ent. text}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
