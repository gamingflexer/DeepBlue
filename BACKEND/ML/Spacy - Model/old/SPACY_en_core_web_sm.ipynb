{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "\n",
    "def extract_text_from_doc(doc_path):\n",
    "   temp = docx2txt.process(doc_path)\n",
    "   text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
    "   return ' '.join(text)\n",
    "\n",
    "path = \"vihark.docx\"\n",
    "text = extract_text_from_doc(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAME FIRST & LAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(resume_text):\n",
    "   nlp_text = nlp(resume_text)\n",
    "  \n",
    "   # First name and Last name are always Proper Nouns\n",
    "   pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "  \n",
    "   matcher.add('NAME', None, pattern)\n",
    "  \n",
    "   matches = matcher(nlp_text)\n",
    "  \n",
    "   for match_id, start, end in matches:\n",
    "       span = nlp_text[start:end]\n",
    "       return span.text\n",
    "\n",
    "name = extract_name(text)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
