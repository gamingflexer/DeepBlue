{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ec9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2171fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pickle.load(open('train_data_700.pkl','rb')) #trying model 2 bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea97956",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1= pickle.load(open('train_data.pkl','rb')) #trying model 2 bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ed725d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['entities_mapped'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3035b2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_content', 'entities_mapped'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b7f80a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2h/lw5rv90j0ln7v084d1vkrcg80000gn/T/ipykernel_83422/1353130999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Loading spacy trained-blank model - en - english\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "#Loading spacy trained-blank model - en - english\n",
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa5fd766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the traning model\n",
    "\n",
    "def train_model(train_data):\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner=nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner,last=True)\n",
    "        \n",
    "    for _, annotation in train_data:\n",
    "        for ent in annotation['entities']:\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "# Now to remove other pipelines - we define this here - READ SPACY WEBSITE\n",
    "\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "            optimizer = nlp.begin_training()\n",
    "            for itn in range(50):\n",
    "                print(\"Statring iteration \" + str(itn))\n",
    "                random.shuffle(train_data)\n",
    "                losses = {}\n",
    "                index = 0\n",
    "                for text, annotations in train_data:\n",
    "                    try:\n",
    "                        nlp.update(\n",
    "                            [text],  # batch of texts\n",
    "                            [annotations],  # batch of annotations\n",
    "                            drop=0.2,  # dropout - make it harder to memorise data\n",
    "                            sgd=optimizer,  # callable to update weights\n",
    "                            losses=losses)\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                    \n",
    "                print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832fb184",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2h/lw5rv90j0ln7v084d1vkrcg80000gn/T/ipykernel_83422/3750099008.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Passing the trained data & TRAINNING DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "#Passing the trained data & TRAINNING DATA\n",
    "\n",
    "train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f5ee882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "nlp.to_disk('nlp_model_V0.3_45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6e9377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load this already trained model - we use this\n",
    "model = 'nlp_model_V0.3_45'\n",
    "nlp_model = spacy.load(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f133dc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Sanand Pal SQL and MSBI Developer with experience in Azure SQL and Data Lake store.  Hyderabad, Telangana - Email me on Indeed: indeed.com/r/Sanand-Pal/5c99c42c3400737c  I intend to establish myself as Software Engineer / architect with an integrated business solution provider through a long time commitment, contributing to the company's growth and in turn ensuring personal growth within the organization. I believe that my technical, functional and communication skills will enable me in facing the challenging career ahead.  Willing to relocate to: Kolkata, West Bengal - hyderbad, Telangana  WORK EXPERIENCE  Assistant Consultant  TCS  • Expertise in SQL Server(2008 R2, 2012, 2014) development, Microsoft BI (SSIS) • Experience with Microsoft BI (SSAS, SSRS), ASP.NET, VSTO, C#. • Experience in all the phases of Software Development Life Cycle (SDLC). • Experience in Business Requirements Analysis, meeting customer expectations. • Have had the opportunity to handle and work in multiple projects at a time. • Experience in working both independently and in a team-oriented, collaborative environment. • Excellent written and verbal communication skills, good analytical and problem solving skills.  SQL and SSIS developer/Sustain resource  MICROSOFT -  Hyderabad, Telangana -  August 2011 to June 2016  Project US EPG Forecast Workbook (FWB) application is designed to support the US Enterprise Partner Group (US EPG) in producing and maintaining the monthly US sales forecast. It is a transactional database combined with Microsoft Office Excel functionality that enables end users to interact with the USNAForecast database. Typically, an ATU manager will connect to the corporate network and download data from the forecast database, which creates an offline forecast workbook. This data can then be accessed offline, modelled, and changes to certain data fields are subsequently uploaded back to the forecast database through a CorpNet connection. These changes are then stored in the online database and subsequently loaded back into upstream systems.  Responsibilities • Involved in the Technical discussions/Sessions and efforts estimations and reviews. • Involved in analysis of the Bugs/ Issues/defects/CRs. • Involved in change requests on VSTO Excel application. • Involved in design of database, tables and stored procedures. • Developed SQL Server Integration Services packages for ETL process. • Unit testing and bug fixing of the code.  https://www.indeed.com/r/Sanand-Pal/5c99c42c3400737c?isid=rex-download&ikw=download-top&co=IN   • Actively solved the issues that raised during the integration cycle • Performed build verification and Smoke tested all the defects raised before giving a delivery. • Prepared and updated FS, TS and deployment guides. • Provided knowledge sharing to Users • Provided post implementation support • Promptly check in the final Code in VSTF.  Hyderabad, India  EDUCATION  Bachelor of Technology in Branch  East Point College of Engg. & Tech. -  Bengaluru, Karnataka  June 2006 to July 2010  SKILLS  Sql Server, Ssis, T-SQL, ETL, SSRS\",\n",
       " {'entities': [(3056, 3090, 'Skills'),\n",
       "   (3042, 3046, 'Graduation Year'),\n",
       "   (2963, 2998, 'College Name'),\n",
       "   (2929, 2961, 'Degree'),\n",
       "   (2900, 2910, 'Location'),\n",
       "   (2474, 2514, 'Email Address'),\n",
       "   (1263, 1273, 'Location'),\n",
       "   (636, 640, 'Companies worked at'),\n",
       "   (615, 635, 'Designation'),\n",
       "   (128, 168, 'Email Address'),\n",
       "   (85, 95, 'Location'),\n",
       "   (11, 33, 'Designation'),\n",
       "   (0, 10, 'Name')]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "235e4679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                           - Sanand Pal\n",
      "DESIGNATION                    - SQL and MSBI Developer\n",
      "LOCATION                       - Hyderabad\n",
      "EMAIL ADDRESS                  - indeed.com/r/Sanand-Pal/5c99c42c3400737c\n",
      "LOCATION                       - Kolkata\n",
      "DESIGNATION                    - Assistant Consultant\n",
      "COMPANIES WORKED AT            - TCS\n",
      "COMPANIES WORKED AT            - MICROSOFT\n",
      "DEGREE                         - Bachelor of Technology in Branch\n",
      "SKILLS                         - Sql Server, Ssis, T-SQL, ETL, SSRS\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_model(train_data[0][0])\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.label_.upper():{30}} - {ent.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46302ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "Contact\n",
      "www.linkedin.com/in/adwa-\n",
      "altami-58b2bb188 (LinkedIn)\n",
      "Adwa AlTami\n",
      "Business Analyst Intern at HRcom.io\n",
      "Riyadh\n",
      "Experience\n",
      "E-Commerce Club | ةينورتكلإلا ةراجتلا يدان\n",
      "1 year 1 month\n",
      "President\n",
      "September 2021 - Present (5 months)\n",
      "Vice President\n",
      "January 2021 - September 2021 (9 months)\n",
      "HRcom.io\n",
      "Business Analyst Intern\n",
      "May 2021 - Present (9 months)\n",
      "Riyadh, Saudi Arabia\n",
      "Prince Sultan University - Data Science Club\n",
      "Graphic Designer\n",
      "February 2020 - May 2021 (1 year 4 months)\n",
      "Prince Sultan University - Accounting Club\n",
      "Graphic Designer\n",
      "January 2020 - May 2021 (1 year 5 months)\n",
      "Education\n",
      "Prince Sultan University\n",
      "Information Systems and E-Commerce · (September 2019 - September 2024)\n",
      "AlAfaq Schools\n",
      "American Diploma  · (2019)\n",
      " \n",
      "Page 1 of 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys,fitz\n",
    "fname = 'Profile.pdf'\n",
    "doc = fitz.open(fname)\n",
    "text=\"\"\n",
    "for page in doc:\n",
    "    text = text +str(page.getText())\n",
    "    \n",
    "tx=\" \".join(text.split('\\n'))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e086adeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLLEGE NAME                            -Contact www.linkedin.com/in/adwa- altami-58b2bb188 (LinkedIn) Adwa AlTami Business Analyst\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_model(tx)\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.label_.upper():{40}}-{ent.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80882a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tika in c:\\users\\subodh\\anaconda3\\lib\\site-packages (1.24)\n",
      "Requirement already satisfied: setuptools in c:\\users\\subodh\\anaconda3\\lib\\site-packages (from tika) (58.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\subodh\\anaconda3\\lib\\site-packages (from tika) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\subodh\\anaconda3\\lib\\site-packages (from requests->tika) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\subodh\\anaconda3\\lib\\site-packages (from requests->tika) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\subodh\\anaconda3\\lib\\site-packages (from requests->tika) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\subodh\\anaconda3\\lib\\site-packages (from requests->tika) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "580fa8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Resume\n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "Contact\n",
      "\n",
      "www.linkedin.com/in/adwa-\n",
      "altami-58b2bb188 (LinkedIn)\n",
      "\n",
      "Adwa AlTami\n",
      "Business Analyst Intern at HRcom.io\n",
      "Riyadh\n",
      "\n",
      "Experience\n",
      "\n",
      "E-Commerce Club | نادي التجارة الإلكترونية\n",
      "1 year 1 month\n",
      "\n",
      "President\n",
      "September 2021 - Present (5 months)\n",
      "\n",
      "Vice President\n",
      "January 2021 - September 2021 (9 months)\n",
      "\n",
      "HRcom.io\n",
      "Business Analyst Intern\n",
      "May 2021 - Present (9 months)\n",
      "Riyadh, Saudi Arabia\n",
      "\n",
      "Prince Sultan University - Data Science Club\n",
      "Graphic Designer\n",
      "February 2020 - May 2021 (1 year 4 months)\n",
      "\n",
      "Prince Sultan University - Accounting Club\n",
      "Graphic Designer\n",
      "January 2020 - May 2021 (1 year 5 months)\n",
      "\n",
      "Education\n",
      "Prince Sultan University\n",
      "Information Systems and E-Commerce · (September 2019 - September 2024)\n",
      "\n",
      "AlAfaq Schools\n",
      "American Diploma  · (2019)\n",
      "\n",
      "  Page 1 of 1\n",
      "\n",
      "https://www.linkedin.com/in/adwa-altami-58b2bb188?jobid=1234&lipi=urn%3Ali%3Apage%3Ad_jobs_easyapply_pdfgenresume%3BSBBlAlIoQiKcpuZ5mdSkjA%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_jobs_easyapply_pdfgenresume-v02_profile\n",
      "https://www.linkedin.com/in/adwa-altami-58b2bb188?jobid=1234&lipi=urn%3Ali%3Apage%3Ad_jobs_easyapply_pdfgenresume%3BSBBlAlIoQiKcpuZ5mdSkjA%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_jobs_easyapply_pdfgenresume-v02_profile\n",
      "\n",
      "\n",
      "Resume   Contactwww.linkedin.com/in/adwa-altami-58b2bb188 (LinkedIn)Adwa AlTamiBusiness Analyst Intern at HRcom.ioRiyadhExperienceE-Commerce Club | نادي التجارة الإلكترونية1 year 1 monthPresidentSeptember 2021 - Present (5 months)Vice PresidentJanuary 2021 - September 2021 (9 months)HRcom.ioBusiness Analyst InternMay 2021 - Present (9 months)Riyadh, Saudi ArabiaPrince Sultan University - Data Science ClubGraphic DesignerFebruary 2020 - May 2021 (1 year 4 months)Prince Sultan University - Accounting ClubGraphic DesignerJanuary 2020 - May 2021 (1 year 5 months)EducationPrince Sultan UniversityInformation Systems and E-Commerce · (September 2019 - September 2024)AlAfaq SchoolsAmerican Diploma  · (2019)  Page 1 of 1https://www.linkedin.com/in/adwa-altami-58b2bb188?jobid=1234&lipi=urn%3Ali%3Apage%3Ad_jobs_easyapply_pdfgenresume%3BSBBlAlIoQiKcpuZ5mdSkjA%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_jobs_easyapply_pdfgenresume-v02_profilehttps://www.linkedin.com/in/adwa-altami-58b2bb188?jobid=1234&lipi=urn%3Ali%3Apage%3Ad_jobs_easyapply_pdfgenresume%3BSBBlAlIoQiKcpuZ5mdSkjA%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_jobs_easyapply_pdfgenresume-v02_profile\n"
     ]
    }
   ],
   "source": [
    "from tika import parser # pip install tika\n",
    "raw = parser.from_file('Profile.pdf')\n",
    "print(raw['content'])\n",
    "\n",
    "# removing spacing between lines    \n",
    "tx = \"\".join(raw['content'].split('\\n'))\n",
    "print (tx)\n",
    "\n",
    "#and then add the test data oce again \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e548871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have data in similarly segreagetd form we can use this otherwise not\n",
    "\n",
    "doc = nlp_model(raw['content']) # add the data varaible in the brackets\n",
    "for ent in doc.ents:\n",
    "    print (f'{ent.label_.upper():{30}}- {ent.text}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
