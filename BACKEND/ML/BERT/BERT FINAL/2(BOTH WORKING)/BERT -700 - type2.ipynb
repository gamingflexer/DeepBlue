{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw2cQuCkJgeX"
      },
      "source": [
        "# 700"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RjTZFaxJotv",
        "outputId": "5054169d-67b3-4970-df7f-3bef5e785d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Dq5_2ZEvJui9"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_pretrained_bert seqeval transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IKzCIZOMJgeZ",
        "outputId": "b0f7157d-9b94-48f5-b640-4383d5d0484c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing required Libraries\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from seqeval.metrics import f1_score\n",
        "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm,trange\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import re\n",
        "import torch\n",
        "import transformers\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.autograd import Variable\n",
        "\n",
        "tags_vals = ['Empty','UNKNOWN','Email Address', 'Links', 'Skills', 'Graduation Year', 'College Name', 'Degree', 'Companies worked at', 'Location', 'Name', 'Designation', 'projects', 'Years of Experience', 'Can Relocate to', 'Rewards and Achievements', 'Address', 'University', 'Relocate to', 'Certifications', 'state', 'links', 'College', 'training', 'des', 'abc']\n",
        "\n",
        "data_file_address = \"/content/drive/MyDrive/Colab Notebooks/datasets/pre_trained.json\"\n",
        "# Reading data\n",
        "df_data = pd.read_json(data_file_address, lines=True)\n",
        "df_data=df_data.drop(['extras'],axis=1)\n",
        "\n",
        "# Removing New Line characters\n",
        "for i in range(len(df_data)):\n",
        "    df_data[\"content\"][i] = df_data[\"content\"][i].replace(\"\\n\", \" \")\n",
        "df_data.head()\n",
        "\n",
        "#config\n",
        "MAX_LEN = 512   #512 #300\n",
        "bs = 2 #16\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3_95P1FxJgeb"
      },
      "outputs": [],
      "source": [
        "# JSON formatting functions\n",
        "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
        "    try:\n",
        "        training_data = []\n",
        "        lines=[]\n",
        "        with open(dataturks_JSON_FilePath, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            data = json.loads(line)\n",
        "            text = data['content'].replace(\"\\n\", \" \")\n",
        "            entities = []\n",
        "            data_annotations = data['annotation']\n",
        "            if data_annotations is not None:\n",
        "                for annotation in data_annotations:\n",
        "                    #only a single point in text annotation.\n",
        "                    point = annotation['points'][0]\n",
        "                    labels = annotation['label']\n",
        "                    # handle both list of labels or a single label.\n",
        "                    if not isinstance(labels, list):\n",
        "                        labels = [labels]\n",
        "\n",
        "                    for label in labels:\n",
        "                        point_start = point['start']\n",
        "                        point_end = point['end']\n",
        "                        point_text = point['text']\n",
        "                        \n",
        "                        lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
        "                        rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
        "                        if lstrip_diff != 0:\n",
        "                            point_start = point_start + lstrip_diff\n",
        "                        if rstrip_diff != 0:\n",
        "                            point_end = point_end - rstrip_diff\n",
        "                        entities.append((point_start, point_end + 1 , label))\n",
        "            training_data.append((text, {\"entities\" : entities}))\n",
        "        return training_data\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n",
        "        return None\n",
        "\n",
        "def trim_entity_spans(data: list) -> list:\n",
        "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
        "\n",
        "    Args:\n",
        "        data (list): The data to be cleaned in spaCy JSON format.\n",
        "\n",
        "    Returns:\n",
        "        list: The cleaned data.\n",
        "    \"\"\"\n",
        "    invalid_span_tokens = re.compile(r'\\s')\n",
        "\n",
        "    cleaned_data = []\n",
        "    for text, annotations in data:\n",
        "        entities = annotations['entities']\n",
        "        valid_entities = []\n",
        "        for start, end, label in entities:\n",
        "            valid_start = start\n",
        "            valid_end = end\n",
        "            while valid_start < len(text) and invalid_span_tokens.match(\n",
        "                    text[valid_start]):\n",
        "                valid_start += 1\n",
        "            while valid_end > 1 and invalid_span_tokens.match(\n",
        "                    text[valid_end - 1]):\n",
        "                valid_end -= 1\n",
        "            valid_entities.append([valid_start, valid_end, label])\n",
        "        cleaned_data.append([text, {'entities': valid_entities}])\n",
        "    return cleaned_data        \n",
        "\n",
        "data = trim_entity_spans(convert_dataturks_to_spacy(data_file_address))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Laxpk0VjJgec"
      },
      "source": [
        "### Changing data to appropriate format so as to feed it to the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "5cc4c30248e44709a5685f41bdbd3bd9",
            "e3999f1bcdbb49f2a3bfe935664140b1",
            "3a0cdaa680934ba8acddd4c3f5888134",
            "73cf0e1ea5cb4e30b2b0363c66fcd14b",
            "a6d91690dc1141478bfccba77a28d76d",
            "07eab98812b44082aafea9addf36603a",
            "8c8b519e2f5c418f89dcbf6cfd007f45",
            "48c96081744a4285b412af8edaaef893",
            "1013c28be3734003a7fe0416a304ae80",
            "533a26d7588940f5a3290b5d5798cdfd",
            "2a9b3fd59f6541188e0114b78f79a26e"
          ]
        },
        "id": "rD4mMqIHJgec",
        "outputId": "ea50378d-9d19-4664-ccc6-fff9ee0c57b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cc4c30248e44709a5685f41bdbd3bd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/701 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "cleanedDF = pd.DataFrame(columns=[\"setences_cleaned\"])\n",
        "sum1 = 0\n",
        "for i in tqdm(range(len(data))):\n",
        "    start = 0\n",
        "    emptyList = [\"Empty\"] * len(data[i][0].split())\n",
        "    numberOfWords = 0\n",
        "    lenOfString = len(data[i][0])\n",
        "    strData = data[i][0]\n",
        "    strDictData = data[i][1]\n",
        "    lastIndexOfSpace = strData.rfind(' ')\n",
        "    for i in range(lenOfString):\n",
        "        if (strData[i]==\" \" and strData[i+1]!=\" \"):\n",
        "            for k,v in strDictData.items():\n",
        "                for j in range(len(v)):\n",
        "                    entList = v[len(v)-j-1]\n",
        "                    if (start>=int(entList[0]) and i<=int(entList[1])):\n",
        "                        emptyList[numberOfWords] = entList[2]\n",
        "                        break\n",
        "                    else:\n",
        "                        continue\n",
        "            start = i + 1  \n",
        "            numberOfWords += 1\n",
        "        if (i == lastIndexOfSpace):\n",
        "            for j in range(len(v)):\n",
        "                    entList = v[len(v)-j-1]\n",
        "                    if (lastIndexOfSpace>=int(entList[0]) and lenOfString<=int(entList[1])):\n",
        "                        emptyList[numberOfWords] = entList[2]\n",
        "                        numberOfWords += 1\n",
        "    cleanedDF = cleanedDF.append(pd.Series([emptyList],  index=cleanedDF.columns ), ignore_index=True )\n",
        "    sum1 = sum1 + numberOfWords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NCI_TBniJged",
        "outputId": "ef29a0fe-3762-403e-97be-e8576d4eebd8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-17a3a842-74fa-48c2-8994-827e0d1ff33f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>setences_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Name, Name, Empty, Empty, Empty, Empty, Empty...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Name, Name, Designation, Designation, Designa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Name, Name, Designation, Empty, Empty, Empty,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Name, Name, Designation, Designation, Designa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Name, Name, Designation, Empty, Empty, Empty,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17a3a842-74fa-48c2-8994-827e0d1ff33f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17a3a842-74fa-48c2-8994-827e0d1ff33f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17a3a842-74fa-48c2-8994-827e0d1ff33f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    setences_cleaned\n",
              "0  [Name, Name, Empty, Empty, Empty, Empty, Empty...\n",
              "1  [Name, Name, Designation, Designation, Designa...\n",
              "2  [Name, Name, Designation, Empty, Empty, Empty,...\n",
              "3  [Name, Name, Designation, Designation, Designa...\n",
              "4  [Name, Name, Designation, Empty, Empty, Empty,..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleanedDF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wi9SuFukJged"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# totalNumWords = [len(one_comment.split()) for one_comment in df_data[\"content\"]]\n",
        "# plt.hist(totalNumWords)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "3Gnfy-DIJged",
        "outputId": "dee56a6d-c6ea-46aa-bd09-6bf43cbcd570"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a9c2bb2f02a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#tokenizer = Tokenizer(num_words=20000) #SIMPLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2552\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2554\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2555\u001b[0m         )\n\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mis_pretokenized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         )\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
          ]
        }
      ],
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True,max_bytes_per_word=20000)  #BERT\n",
        "tokenizer = BertTokenizerFast('/content/drive/MyDrive/Colab Notebooks/DeepBlue/bert-large-uncased/vocab.txt', lowercase=True)\n",
        "# tokenizer.tokenize(df_data[\"content\"])\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=20000) #SIMPLE\n",
        "tokenizer.fit_on_texts(df_data[\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daGqxHJkJgee",
        "outputId": "9989c0ca-6837-4d0a-d79e-3b7a9d6f86fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4659, 4660, 627, 493, 6, 4661, 1422, 5, 1131, 34, 5971, 21, 55, 50, 10, 12, 12, 17, 19, 4659, 4660, 5972, 75, 4295, 3, 506, 104, 85, 24, 1, 3395, 315, 3, 427, 273, 14, 494, 1, 26, 1242, 289, 171, 536, 5973, 5, 420, 1243, 1, 26, 3, 617, 5, 104, 26, 26, 22, 627, 493, 6, 4661, 1422, 5, 1131, 34, 270, 522, 1567, 382, 214, 1112, 32, 9018, 3396, 1567, 1, 433, 9019, 9020, 4296, 2, 797, 523, 235, 2, 871, 96, 56, 3397, 5974, 4297, 3925, 101, 421, 6, 2055, 5, 54, 139, 2860, 89, 1645, 1645, 21, 81, 24, 151, 59, 48, 27, 34, 558, 59, 48, 27, 34, 341, 59, 48, 27, 34, 69, 403, 59, 48, 27, 34, 69, 161, 59, 48, 27, 34, 95, 54, 63, 24, 2, 488, 417, 99, 99, 165, 276, 1267, 2, 169, 369, 558, 920, 2, 283, 116, 161, 858, 161, 105, 375, 341, 2, 151, 134, 403, 134, 98, 105, 156, 88, 1490, 893, 39, 37, 12, 17, 19, 4659, 4660, 5972, 41, 42, 18, 43, 18, 36, 33, 5]\n"
          ]
        }
      ],
      "source": [
        "tokenized_texts = tokenizer.texts_to_sequences(df_data[\"content\"])\n",
        "# tokenized_texts = [tokenizer.tokenize(sent) for sent in df_data[\"content\"]]\n",
        "print(tokenized_texts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tOlaEvoHJgee"
      },
      "outputs": [],
      "source": [
        "input_ids = pad_sequences(tokenized_texts,\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TiERUYivJgee"
      },
      "outputs": [],
      "source": [
        "tag2idx = {t: i for i, t in enumerate(tags_vals)} #list of tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U4hqsWimJgef"
      },
      "outputs": [],
      "source": [
        "labels = cleanedDF[\"setences_cleaned\"].tolist() #labeling the tokens of tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5lx4hehyJgef"
      },
      "outputs": [],
      "source": [
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"Empty\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "#tagging then tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aE37GufNJgef"
      },
      "outputs": [],
      "source": [
        "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gzsVQnncJgef"
      },
      "outputs": [],
      "source": [
        "#splitting of dataset #input & #targets\n",
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3wDASqMwJgef"
      },
      "outputs": [],
      "source": [
        "#tranning dataset - final - 3 each\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck6qKPZ7Jgeg"
      },
      "source": [
        "- tr_inputs = content\n",
        "- tr_maks = starting id\n",
        "- tr_inputs = ending id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Sn6y32apJgeg"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags) #tr_inputs = content\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTResumeParser(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTResumeParser,self).__init__()\n",
        "        self.bert = transformers.BertForTokenClassification.from_pretrained(\"bert-base-uncased\")\n",
        "        self.bert_drop = nn.Dropout\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qP1XeBxFJgeg"
      },
      "outputs": [],
      "source": [
        "model = BertForTokenClassification.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/DeepBlue/bert-large-uncased\", num_labels=len(tag2idx))\n",
        "model.cuda();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kHHXwlTJgeg"
      },
      "source": [
        "## Fine Tunning\n",
        "#### MAX_LEN = 300 & bs = 16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NAwV9xKqJgeg"
      },
      "outputs": [],
      "source": [
        "epochs = 11 #tune accordinling\n",
        "max_grad_norm = 1.0 #helps to avoid gradient exploding #1 deaulft -1 means no clipping\n",
        "\n",
        "FULL_FINETUNING = True\n",
        "\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5) #1e-6 & 6e-5 also good"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kRBDbkRlJgeh"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JkhuAnAIL843"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBe3OlN8Jgeh",
        "outputId": "ad1f1808-2b85-42da-f796-f6d4afdb20ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/11 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TRANNING ###########################\n",
            "Train loss: 0.6684394312756402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   9%|▉         | 1/11 [09:30<1:35:08, 570.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5621505507992374\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.5668292888573238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  18%|█▊        | 2/11 [19:00<1:25:33, 570.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5727320354845788\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.574530100349396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  27%|██▋       | 3/11 [28:30<1:16:00, 570.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5572360141409768\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.5633068641026815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  36%|███▋      | 4/11 [38:00<1:06:30, 570.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5568009316921234\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.5707263161738714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  45%|████▌     | 5/11 [47:29<56:58, 569.81s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5442415848374367\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.5753133800294664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  55%|█████▍    | 6/11 [57:00<47:29, 569.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5602916102442477\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.5758254166160311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  64%|██████▎   | 7/11 [1:06:29<37:58, 569.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5614024284813139\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.5753467645436998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  73%|███████▎  | 8/11 [1:15:58<28:28, 569.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5409661192033026\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.5651851830501405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  82%|████████▏ | 9/11 [1:25:27<18:58, 569.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5454558688733313\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.5672862101641912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  91%|█████████ | 10/11 [1:34:57<09:29, 569.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5449373585482439\n",
            "########################### TRANNING ###########################\n",
            "Train loss: 0.5788069307331055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 11/11 [1:44:26<00:00, 569.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################### TESTING ###########################\n",
            "Validation loss: 0.5512735781570276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # TRAIN loop\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # forward pass\n",
        "        loss = model(b_input_ids, token_type_ids=None,\n",
        "                     attention_mask=b_input_mask, labels=b_labels)\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "        \n",
        "    # print train loss per epoch\n",
        "    print('########################### TRANNING ###########################')\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    # VALIDATION on validation set\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in valid_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                                  attention_mask=b_input_mask, labels=b_labels)\n",
        "            logits = model(b_input_ids, token_type_ids=None,\n",
        "                           attention_mask=b_input_mask)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.append(label_ids)\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        \n",
        "        nb_eval_examples += b_input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss/nb_eval_steps\n",
        "    print('########################### TESTING ###########################')\n",
        "    print(\"Validation loss: {}\".format(eval_loss))\n",
        "    #print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "    #print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpuIXkY8NB-h"
      },
      "source": [
        "### CNN LAYER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aweAd7bHNEMn"
      },
      "outputs": [],
      "source": [
        "# tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# bert_model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# def tokenize_text(df, MAX_LEN):\n",
        "#     return [\n",
        "#         tokenizer.encode(text)[:MAX_LEN] for text in df['text']\n",
        "#     ]\n",
        "\n",
        "# def pad_text(tokenized_text, MAX_LEN):\n",
        "#     return np.array([el + [0] * (MAX_LEN - len(el)) for el in tokenized_text])\n",
        "\n",
        "# def tokenize_and_pad_text(df, MAX_LEN):\n",
        "#     tokenized_text = tokenize_text(df, MAX_LEN)\n",
        "#     padded_text = pad_text(tokenized_text, MAX_LEN)\n",
        "#     return torch.tensor(padded_text)\n",
        "\n",
        "# def targets_to_tensor(df):\n",
        "#     return torch.tensor(df['label'].values, dtype=torch.float32)\n",
        "\n",
        "# train_indices = tokenize_and_pad_text(small_train, MAX_LEN)\n",
        "# val_indices = tokenize_and_pad_text(small_valid, MAX_LEN)\n",
        "# test_indices = tokenize_and_pad_text(small_test, MAX_LEN)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     x_train = model(train_indices)[0]  \n",
        "#     x_val = model(val_indices)[0]\n",
        "#     x_test = model(test_indices)[0]\n",
        "\n",
        "# y_train = targets_to_tensor(small_train)\n",
        "# y_val = targets_to_tensor(small_valid)\n",
        "# y_test = targets_to_tensor(small_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZhObKhrNJ6r"
      },
      "outputs": [],
      "source": [
        "lr=3e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "#CLASS\n",
        "class KimCNN(nn.Module):\n",
        "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static): #main layer\n",
        "        super(KimCNN, self).__init__()\n",
        "        V = embed_num\n",
        "        D = embed_dim\n",
        "        C = class_num\n",
        "        Co = kernel_num\n",
        "        Ks = kernel_sizes\n",
        "\n",
        "        self.static = static\n",
        "        self.embed = nn.Embedding(V, D)\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x): #forward pass\n",
        "        if self.static:\n",
        "            x = Variable(x)\n",
        "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "        logit = self.fc1(x)  # (N, C)\n",
        "        output = self.sigmoid(logit)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "def generate_batch_data(x, y, bs):\n",
        "    i, batch = 0, 0\n",
        "    for batch, i in enumerate(range(0, len(x) - bs, bs), 1):\n",
        "        x_batch = x[i : i + bs]\n",
        "        y_batch = y[i : i + bs]\n",
        "        yield x_batch, y_batch, batch\n",
        "    if i + bs < len(x):\n",
        "        yield x[i + bs :], y[i + bs :], batch + 1\n",
        "    if batch == 0:\n",
        "        yield x, y, 1\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train(True)\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, bs):\n",
        "        y_pred = model(x_batch)\n",
        "        y_batch = y_batch.unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= batch\n",
        "    train_losses.append(train_loss)\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    model.eval() # disable dropout for deterministic output\n",
        "    with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "        val_loss, batch = 0, 1\n",
        "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, bs):\n",
        "            y_pred = model(x_batch)\n",
        "            y_batch = y_batch.unsqueeze(1)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            val_loss += loss.item()\n",
        "        val_loss /= batch\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    print(\n",
        "        \"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs.\"\n",
        "        % (epoch + 1, train_losses[-1], val_losses[-1], elapsed)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KssZ_olJgeh"
      },
      "source": [
        "### SAVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lHgf5hLx7s9m"
      },
      "outputs": [],
      "source": [
        "torch.save(\n",
        "    {\n",
        "        \"epoch\": epochs,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    '/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/uncased/new/model_700-512-basedir.tar',\n",
        ")\n",
        "\n",
        "##\n",
        "output_model = '/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/uncased/new/large-uncased-bert-700-512-basedir.pth'\n",
        "\n",
        "def save(model, optimizer):\n",
        "    # save\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, output_model)\n",
        "\n",
        "save(model, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-pnwXFqh5r2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from pytorch_pretrained_bert import BertForSequenceClassification\n",
        "\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/700/\")\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/700/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LOe9a9_k6UdP"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/uncased/new/model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNI--8mfJgeh"
      },
      "outputs": [],
      "source": [
        "#M0\n",
        "torch.save(\n",
        "    {\n",
        "        \"epoch\": epochs,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    '/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/700/model_300-512.tar',\n",
        ")\n",
        "\n",
        "#M1\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/700/mode.pt')\n",
        "\n",
        "#M2\n",
        "# save\n",
        "output_model = '/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/700/large-uncased-bert-700-512.pth'\n",
        "\n",
        "def save(model, optimizer):\n",
        "    # save\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, output_model)\n",
        "\n",
        "save(model, optimizer)\n",
        "\n",
        "#load\n",
        "checkpoint = torch.load(output_model, map_location='cpu')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "\n",
        "#M3\n",
        "from transformers import AutoTokenizer\n",
        "from pytorch_pretrained_bert import BertForSequenceClassification\n",
        "\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Models/DeepBlue/Auto Tokenizer/large-uncased-bert-30\")\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Models/DeepBlue/Auto Tokenizer/large-uncased-bert-30\")\n",
        "\n",
        "#M4\n",
        "import json\n",
        "json.dump(model.to_json(), open(\"/content/drive/MyDrive/Colab Notebooks/Models/DeepBlue/Auto Tokenizer/large-uncased-bert-300.json\", \"w\"))\n",
        "\n",
        "\n",
        "# STATE_DICT = torch.load('../input/ner-resume/model_e6.tar', map_location=DEVICE)\n",
        "# TOKENIZER = BertTokenizerFast('../input/bert-base-uncased/vocab.txt', lowercase=True)\n",
        "# MODEL = BertForTokenClassification.from_pretrained(MODEL_PATH, state_dict=STATE_DICT['model_state_dict'], num_labels=12)\n",
        "# #M5\n",
        "# torch.save(\n",
        "#     {'model_state_dict': STATE_DICT['model_state_dict']},\n",
        "#     'state.bin'\n",
        "# )\n",
        "\n",
        "# #M6\n",
        "# joblib.dump({'model_state_dict': STATE_DICT['model_state_dict']}, 'state.gz', compress=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqf3b9KpJgeh"
      },
      "source": [
        "## PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhLYU_zwiD7q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "output_model = \"/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/uncased/new/model\"\n",
        "\n",
        "#load\n",
        "checkpoint = torch.load(output_model, map_location='cpu')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H78idY-IkF7v"
      },
      "outputs": [],
      "source": [
        "!pip install tika textract --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSIr8uH2Jgeh",
        "outputId": "b68b359f-3f2f-4b54-c427-9c30bd7c4218"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-10 11:22:38,314 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar to /tmp/tika-server.jar.\n",
            "2022-02-10 11:22:39,632 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar.md5 to /tmp/tika-server.jar.md5.\n",
            "2022-02-10 11:22:40,563 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "Ayush Srivastava \n",
            "Web Developer \n",
            "Final year ​B.Tech​ student with ​3+​ years of experience in building \n",
            "web applications, college projects, freelancing, and contributing to \n",
            "Open Source Softwares. \n",
            "\n",
            "JSS Boys Hostel, C Block, \n",
            "Sector - 62, Noida. \n",
            "(+91) 9599025432 \n",
            "srivastavs61@gmail.com \n",
            "linkedin.com/in/geekayush \n",
            "github.com/geekayush \n",
            "geekayush.github.io \n",
            "\n",
            "EXPERIENCE \n",
            "\n",
            "1mg​ ​— ​Software Engineer Intern \n",
            "Jan 2020 - Present \n",
            "\n",
            "Avanti Learning Centres​ ​— ​Data Visualization Analyst \n",
            "Jul 2019 - Aug 2019 \n",
            "\n",
            "Responsibilities \n",
            "\n",
            "Task 1 - Report card generator \n",
            "\n",
            "Task 2 - Automate student summary generation in bulk \n",
            "\n",
            "Motion Invite​ ​— ​UI/UX & Front-end Developer \n",
            "Jan 2018 - Mar 2018 \n",
            "\n",
            "Responsibilities \n",
            "\n",
            "Task 1 - Redesign the existed website \n",
            "\n",
            "Task 2 - Develop the redesigned version \n",
            "\n",
            "Edcams​ — ​Front-end Developer \n",
            "Nov 2017 - Jan 2018 \n",
            "\n",
            "Responsibilities \n",
            "\n",
            "Task 1 - Fix the bugs \n",
            "\n",
            "Task 2 - Develop a new sign up portal \n",
            "\n",
            "EDUCATION \n",
            "\n",
            "JSSATE, ​Noida — ​B.Tech \n",
            "2016 - Present \n",
            "\n",
            "● Average Percentage - 74.20% \n",
            "● Coursework included \n",
            "\n",
            "○ Algorithms \n",
            "○ Data Structures \n",
            "○ SQL based DBMS \n",
            "○ Turing Machines \n",
            "○ OS Concepts \n",
            "\n",
            "● Have taken hands-on workshops on \n",
            "○ C/C++ Programming \n",
            "○ Designing (UI/UX & Photoshop) \n",
            "○ Web Development (HTML & CSS) \n",
            "\n",
            "SKILLS \n",
            "\n",
            "Frontend: \n",
            "ReactJS, Gatsby, jQuery, JavaScript, \n",
            "HTML, CSS, Materialize, Bootstrap, \n",
            "Bulma \n",
            " \n",
            "Backend: ​Flask \n",
            "\n",
            "Data Visualization: ​D3, Matplotlib \n",
            "\n",
            "Data Analysis: ​Pandas \n",
            " \n",
            "Cloud Suite: ​Google Cloud Platform \n",
            " \n",
            "Programming Languages: ​C++, C, \n",
            "Python \n",
            " \n",
            "Database: ​Oracle SQL \n",
            "\n",
            "Data Structures and Algorithms in \n",
            "C++ \n",
            "\n",
            "Agile/Scrum and Design thinking \n",
            "approaches \n",
            "\n",
            "ACHIEVEMENTS \n",
            "\n",
            "Special mention ​at ​DevFest \n",
            "Noida​-18 for ​FitMo​ (React-based \n",
            "native application gamifying the \n",
            "motivation towards fitness) \n",
            "\n",
            "Among​ top 10 national finalists ​at \n",
            "Social Track organized by \n",
            "ECell-IITK \n",
            "\n",
            "Second runner-up at B-Plan \n",
            "competition organized by ​ATTAC \n",
            "NGO \n",
            "\n",
            " \n",
            "\n",
            "mailto:srivastavs61@gmail.com\n",
            "https://www.linkedin.com/in/geekayush/\n",
            "http://github.com/geekayush\n",
            "http://geekayush.github.io/\n",
            "https://www.1mg.com/\n",
            "https://avanti.in/\n",
            "http://www.motioninvite.com/\n",
            "https://www.edcams.com/\n",
            "https://github.com/Ayukha/FitMo\n",
            "\n",
            "\n",
            "Avanti Fellows \n",
            "2015 - 2016 \n",
            "\n",
            "● Cleared zonal test to get selected among the top 4 students \n",
            "to receive a full one-year scholarship to study for \n",
            "engineering entrance examinations \n",
            "\n",
            "● Cleared JEE Mains \n",
            "○ 97.90 (All India Percentile Score) \n",
            "○ 44,344 (CRL Rank) \n",
            "\n",
            "● Cleared JEE Advanced \n",
            "○ 18052 (CRL Rank) \n",
            "\n",
            "● Cleared UPSEE \n",
            "○ 4880 (General open rank) \n",
            "\n",
            "CBSE \n",
            "2000 - 2015 \n",
            "\n",
            "● Stood 1st in SOF NCO at the school-level and 10th at the \n",
            "city-level \n",
            "\n",
            "● Passed 10th - 9.8 CGPA \n",
            "● Passed 12th - 90% \n",
            "\n",
            " \n",
            "\n",
            "PROJECTS \n",
            "\n",
            "Know Your College​ ​— ​React-based web app to explore \n",
            "college \n",
            "A web application which will help students and faculties of JSSATE \n",
            "to explore various sections of the college. Developed on ReactJS \n",
            "with backend on NodeJS. ​Link​ (Beta) \n",
            "\n",
            "Code Compiler​ ​— ​Competitive Programming playground \n",
            "A set of programming questions with an online IDE to compile and \n",
            "check whether the program clears the tasks or not. A leaderboard to \n",
            "display standings. ​Link \n",
            "\n",
            "Sherlocked​ ​— ​Quiz game \n",
            "A web quiz based on the theme of Sherlock Holmes where a \n",
            "participant must answer a question within a running time limit. \n",
            "\n",
            "OPEN SOURCE CONTRIBUTIONS \n",
            "\n",
            "CloudCV - EvalAI \n",
            "\n",
            "CloudCV - Origami \n",
            "\n",
            "Open Policy Agent - opa \n",
            "\n",
            "Creative Commons - \n",
            "cccatalogfrontend \n",
            "Fossasia - summit.fossasia.org \n",
            "Open Climate Fix - website \n",
            "Facebook - react-360 \n",
            "Sapient Global Markets - \n",
            "react-querybuilder \n",
            "Anitab-org - mentorship-backend \n",
            "Material Components - \n",
            "material-components-web-react \n",
            "Uber - Manifold \n",
            "\n",
            "CERTIFICATIONS \n",
            "\n",
            "HTML Fundamentals \n",
            "\n",
            "CSS Fundamentals \n",
            "\n",
            "SQL Fundamentals \n",
            "\n",
            "INTERESTS \n",
            "\n",
            "Web Development \n",
            "\n",
            "Machine Learning \n",
            "\n",
            "Automation \n",
            "\n",
            "POSITIONS OF RESPONSIBILITY \n",
            "\n",
            "Head of Web Club ​— ​Nibble Computer Society​ (Official society of CSE Department) \n",
            "\n",
            "Technical Head ​— ​Entrepreneurship Development Cell​ ​(Official E-CELL of JSSATE) \n",
            "\n",
            "Operations/Technical Head ​— ​E-Summit’19 NOIDA \n",
            "\n",
            "https://github.com/ncs-jss/Proj_kc01\n",
            "http://kyc.surge.sh/\n",
            "https://github.com/shobhit1997/Code_Compiler\n",
            "http://52.91.35.65:8000/\n",
            "https://github.com/Ayukha/sherlocked2018\n",
            "https://github.com/Cloud-CV/EvalAI/issues?q=author%3Ageekayush\n",
            "https://github.com/Cloud-CV/Origami/issues?q=author%3Ageekayush\n",
            "https://github.com/open-policy-agent/opa/issues?q=author%3Ageekayush\n",
            "https://github.com/creativecommons/cccatalog-frontend/issues?q=author%3Ageekayush+\n",
            "https://github.com/creativecommons/cccatalog-frontend/issues?q=author%3Ageekayush+\n",
            "https://github.com/fossasia/summit.fossasia.org/issues?q=author%3Ageekayush+\n",
            "https://github.com/openclimatefix/website/issues?q=author%3Ageekayush\n",
            "https://github.com/facebook/react-360/issues?q=author%3Ageekayush\n",
            "https://github.com/sapientglobalmarkets/react-querybuilder/issues?q=author%3Ageekayush\n",
            "https://github.com/sapientglobalmarkets/react-querybuilder/issues?q=author%3Ageekayush\n",
            "https://github.com/anitab-org/mentorship-backend/issues?q=author%3Ageekayush\n",
            "https://github.com/material-components/material-components-web-react/issues?q=author%3Ageekayush\n",
            "https://github.com/material-components/material-components-web-react/issues?q=author%3Ageekayush\n",
            "https://github.com/uber/manifold/issues?q=author%3Ageekayush+\n",
            "https://www.sololearn.com/Certificate/1014-14673013/pdf/\n",
            "https://www.sololearn.com/Certificate/1023-14673013/pdf/\n",
            "https://www.sololearn.com/Certificate/1060-14673013/pdf/\n",
            "http://hackncs.com/\n",
            "http://edcjss.in/\n",
            "https://www.facebook.com/events/331126657549283/\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import textract\n",
        "import re\n",
        "from tika import parser \n",
        "fname = '/content/drive/MyDrive/Colab Notebooks/DeepBlue/Test- Resumes/test.pdf'\n",
        "\n",
        "# text1 = textract.process('/content/drive/MyDrive/Colab Notebooks/Models/DeepBlue/Test- Resumes/Profile.pdf')\n",
        "# text2 = textract.process('/content/drive/MyDrive/Colab Notebooks/Models/DeepBlue/Test- Resumes/test.pdf')\n",
        "\n",
        "raw = parser.from_file(fname)\n",
        "print(raw['content'])\n",
        "\n",
        "####################\n",
        "text = raw['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g3Eq9GiWJgei"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForTokenClassification, BertTokenizerFast\n",
        "import torch\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "\n",
        "#use transformers of choice\n",
        "\n",
        "MAX_LEN = 512\n",
        "EPOCHS = 6\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/DeepBlue/bert-large-uncased'\n",
        "STATE_DICT = torch.load('/content/drive/MyDrive/Colab Notebooks/DeepBlue/TYPE 2/uncased/new/large-uncased-bert-700-512-basedir.pth', map_location=DEVICE)\n",
        "#TOKENIZER = BertTokenizerFast('/content/drive/MyDrive/Colab Notebooks/DeepBlue/bert-large-uncased/vocab.txt', lowercase=True)\n",
        "TOKENIZER = Tokenizer(num_words=20000) #SIMPLE\n",
        "MODEL = BertForTokenClassification.from_pretrained(MODEL_PATH, state_dict=STATE_DICT['model_state_dict'], num_labels=26)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXfTkhRaYzYY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5CLh1hR6aqz"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from transformers import *\n",
        "# tokenizer = BertTokenizer.from_pretrained('./saved_model/')\n",
        "# config = BertConfig('./saved_model/config.json')\n",
        "# model = BertModel(config)\n",
        "# model.load_state_dict(torch.load('./saved_model/pytorch_model.bin', map_location=torch.device('cpu')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "miqDDRTGJgei"
      },
      "outputs": [],
      "source": [
        "#700\n",
        "tags_vals = ['Empty','UNKNOWN','Email Address', 'Links', 'Skills', 'Graduation Year', 'College Name', 'Degree', 'Companies worked at', 'Location', 'Name', 'Designation', 'projects', 'Years of Experience', 'Can Relocate to', 'Rewards and Achievements', 'Address', 'University', 'Relocate to', 'Certifications', 'state', 'links', 'College', 'training', 'des', 'abc']\n",
        "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "idx2tag = {i:t for i, t in enumerate(tags_vals)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PDbiaDvEJgei"
      },
      "outputs": [],
      "source": [
        "#TOKENIZER = BertTokenizerFast('/content/drive/MyDrive/Colab Notebooks/DeepBlue/bert-large-uncased/vocab.txt', lowercase=True)\n",
        "TOKENIZER = Tokenizer(num_words=20000) #SIMPLE\n",
        "\n",
        "def process_resume2(text, tokenizer, max_len):\n",
        "    tok = tokenizer.fit_on_texts(text,return_offsets_mapping=True)\n",
        "    \n",
        "    curr_sent = dict()\n",
        "    \n",
        "    padding_length = max_len - len(tok['input_ids'])\n",
        "        \n",
        "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
        "    curr_sent['token_type_ids'] = tok['token_type_ids'] + ([0] * padding_length)\n",
        "    curr_sent['attention_mask'] = tok['attention_mask'] + ([0] * padding_length)\n",
        "    \n",
        "    final_data = {\n",
        "        'input_ids': torch.tensor(curr_sent['input_ids'], dtype=torch.long),\n",
        "        'token_type_ids': torch.tensor(curr_sent['token_type_ids'], dtype=torch.long),\n",
        "        'attention_mask': torch.tensor(curr_sent['attention_mask'], dtype=torch.long),\n",
        "        'offset_mapping': tok['offset_mapping']\n",
        "    }\n",
        "    \n",
        "    return final_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "t7cjNQCqJgei"
      },
      "outputs": [],
      "source": [
        "def predict(model, tokenizer, idx2tag, tag2idx, device, text):\n",
        "    model.eval()\n",
        "    data = process_resume2(text, tokenizer, MAX_LEN)\n",
        "    input_ids, input_mask = data['input_ids'].unsqueeze(0), data['attention_mask'].unsqueeze(0)\n",
        "    labels = torch.tensor([1] * input_ids.size(0), dtype=torch.long).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids,\n",
        "            token_type_ids=None,\n",
        "            attention_mask=input_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        tmp_eval_loss, logits = outputs[:2]\n",
        "    \n",
        "    logits = logits.cpu().detach().numpy()\n",
        "    label_ids = np.argmax(logits, axis=2)\n",
        "    \n",
        "    entities = []\n",
        "    for label_id, offset in zip(label_ids[0], data['offset_mapping']):\n",
        "        curr_id = idx2tag[label_id]\n",
        "        curr_start = offset[0]\n",
        "        curr_end = offset[1]\n",
        "        if curr_id != 'O':\n",
        "            if len(entities) > 0 and entities[-1]['entity'] == curr_id and curr_start - entities[-1]['end'] in [0, 1]:\n",
        "                entities[-1]['end'] = curr_end\n",
        "            else:\n",
        "                entities.append({'entity': curr_id, 'start': curr_start, 'end':curr_end})\n",
        "    for ent in entities:\n",
        "        ent['text'] = text[ent['start']:ent['end']]\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "EvHxeDVnJgei",
        "outputId": "541ce2a0-b943-4c76-ca0b-8145006db876"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-eeeceed6b0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mentities1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOKENIZER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-b38eec35f17e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, tokenizer, idx2tag, tag2idx, device, text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_resume2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-75754b2e2ad1>\u001b[0m in \u001b[0;36mprocess_resume2\u001b[0;34m(text, tokenizer, max_len)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcurr_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpadding_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcurr_sent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpadding_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "entities1 = predict(MODEL, TOKENIZER, idx2tag, tag2idx, DEVICE, text)\n",
        "\n",
        "for i in entities1:\n",
        "    print(i['entity'], '-', i['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Vg6WySClYVIR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fpuIXkY8NB-h",
        "5KssZ_olJgeh"
      ],
      "name": "BERT -700 - type2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07eab98812b44082aafea9addf36603a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1013c28be3734003a7fe0416a304ae80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9b3fd59f6541188e0114b78f79a26e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a0cdaa680934ba8acddd4c3f5888134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c8b519e2f5c418f89dcbf6cfd007f45",
            "placeholder": "​",
            "style": "IPY_MODEL_07eab98812b44082aafea9addf36603a",
            "value": "100%"
          }
        },
        "48c96081744a4285b412af8edaaef893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "533a26d7588940f5a3290b5d5798cdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cc4c30248e44709a5685f41bdbd3bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a0cdaa680934ba8acddd4c3f5888134",
              "IPY_MODEL_73cf0e1ea5cb4e30b2b0363c66fcd14b",
              "IPY_MODEL_a6d91690dc1141478bfccba77a28d76d"
            ],
            "layout": "IPY_MODEL_e3999f1bcdbb49f2a3bfe935664140b1"
          }
        },
        "73cf0e1ea5cb4e30b2b0363c66fcd14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1013c28be3734003a7fe0416a304ae80",
            "max": 701,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48c96081744a4285b412af8edaaef893",
            "value": 701
          }
        },
        "8c8b519e2f5c418f89dcbf6cfd007f45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6d91690dc1141478bfccba77a28d76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a9b3fd59f6541188e0114b78f79a26e",
            "placeholder": "​",
            "style": "IPY_MODEL_533a26d7588940f5a3290b5d5798cdfd",
            "value": " 701/701 [00:08&lt;00:00, 74.38it/s]"
          }
        },
        "e3999f1bcdbb49f2a3bfe935664140b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
